# ETL-процесса по обработке сделок клиентов: [Test DEMO]
by Oleksandr Husiev

## 1. Запуск вручну
Локальний запуск / інструкція:
    Рекомендовано створити віртуальне середовище (тестовано на conda) і встановити залежності:
        python -m pip install --upgrade pip
        python -m pip install -r requirements.txt

>Якщо використовуєте conda: 

    conda create -n etl python=3.10.19; 
    conda activate etl; pip install -r requirements.txt

Тестовано локально на miniconda `Python 3.10.19`. Запуск через термінал:
1. Перейти в теку проєкту
2. python etl_weekly_trades.py

За замовчуванням ETL pipeline буде запущено з наступними параметрами:

    out = run_etl(
        input_csv="trades (1) (2) (1).csv",
        sqlite_path="agg_result.db",
        table_name="agg_trades_weekly",
        compute_pnl=True # set True if you provide a market_price.json or a 'pnl' column
    )
У цьому випадку запуску локально буде створено файл *.db в корені проєкту а також  `output/top_clients.xlsx`. Якшо з GitHub Actions , то лише файл бази даних, без Excel/CSV репорту (оскільки це прямо не зазначено в ТЗ, повернення цього файлу завжди можна додати через `etl_weekly_trades.yml`)

## 2. Принцип роботи CI/CD

На прикладі тестового завдання, приписаний '.yml' у .github/workflows задає параметри запуску віртуальної машини (runner) та отримання артефакту. Оскільки у цьому варіанті нічого не розгортається у реальну базу даних, можна сказати, що етап CD фактично відсутній.

У спрощеному вигляді принцип роботи CI/CD я розумію так:
- На кожен, наприклад push/workflow_dispatch, запускається workflow із прописаною job CI. Якщо CI падає, або інші умови що прописані заздалегіть для workflow не були результатом — коміт позначається червоним хрестиком, а CD не запускається.
- Інша job у файлі .yml, умовно — CD, запускається коли тригери шо були виставлені ідентифікували свої умови, а також додаткові умови виставлені в пайплайні. Логіка цих додаткових умов, наприклад - для виконання CD має успішно завершитися CI; if ci.result == 'success'.
- Результати (outputs) передаються з CI → CD через artifacts, щоб у на розгортання потрапила перевірена збірка.
- До того, продакшн може включати ручного підтвердження і branch protection за логікою шоб зламані пуші не потраплять у `main`.

## 3. Масштабування під 100+ млн рядків
### Какие технологии замените/добавите?
Приділив би більше уваги векторизації операцій розрахунків і маніпуляцій, зокрема замінив би ітеративні обчислення на np.where(), pd.crosstab() тощо.
Також варто було б подумати про chunked-обробку великих файлів через read_csv(..., chunksize=...), а також про специфіку розрахунку показників (типу unrealised/realised pnl), в плані коректності розгахунку до/після агрегації даних.

### Какую архитектуру ETL предложите?
Передусім я розглядав би це з точки зору object-oriented підходу. Якщо база даних тут таблична, процес, уявляється, також включає інтеграцію з API та формулювання SQL-запитів, то логічно вибудовувати модульну структуру: набір незалежних блоків-функцій, які легко адаптувати або замінити, і також зручно для тестування та повторного використання, як астин ETL. А також:
- Ітеративне або паралельне виконання jobs (наприклад, за допомогою multiprocessing або GitHub Actions matrix strategy).
- Як додактвоий варіант, опція з точки зору self-hosted runner — тобто виконання GitHub Actions на власному сервері компанії. І також,  в теорії, у цьому контексті сам факт використання GitHub Actions як CI/CD-оркестратора (на противагу Jenkins, Argo, GitLab CI).

### Какие метрики мониторинга ETL вы бы внедрили?
1. Data-quality та performance-тести на етапі extraction: короткий summary по всіх полях (типи даних, наявність NaN/NaT, відсоток пропусків); метрики щодо потенційної кореляції пропусків між колонками; частотність появи різних типів значень, регулярність часових періодів.
2. Моніторинг часу та стабільності виконання пайплайну:
середній час виконання job (Avg job run time), середній час у черзі (Avg job queue time),
Job failure rate, Failed job retries, вимірювання використаних ресурсів середовища та агрегація цих даних не лише в GitHub, а й у внутрішній системі компанії. Потенційно — впровадження стандартизованих code & performance benchmarks.

### Где будут храниться входные и выходные данные?
Залежно від контексту, вхідні та вихідні дані можуть зберігатися по-різному. У тестовому прикладі невеликий вхідний файл розміщується локально в репозиторії, а кожен запуск runner у GitHub Actions створює тимчасове середовище, у якому виконується ETL-job і формується артефакт (наприклад, agg_result.db), що зберігається на стороні GitHub як артифакт; після завершення ран усі тимчасові дані видаляються. 

У більш просунутому сценарії вхідні дані, наприклад, підвантажуються пакетно або інкрементально з корпоративної бази чи хмарного сховища / object-based storage, а вихідні — записуються у "тестову" staging базу данних, чи експортуються у форматах CSV/Parquet для подальшої аналітики (звісно і в перспективі на production database). В цому плані законекчена бабліотека sqlite3 — як локальний варіант перед, наприклад, Postgres/MySQL.
